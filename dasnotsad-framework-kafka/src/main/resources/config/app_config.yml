kafka:
  bootstrap:
    #servers: 172.16.0.217:9092,172.16.0.218:9092,172.16.0.219:9092
    security:
    #sasl.mechanism: PLAIN #sasl认证需设置
    #security.protocol: SASL_PLAINTEXT #sasl认证需设置
  producer:
    key.serializer: org.apache.kafka.common.serialization.StringSerializer #必填，key序列化类型（由topic+headers+ProducerRecord里的key构成，通常用String即可）
    value.serializer: org.apache.kafka.common.serialization.ByteArraySerializer #必填，value序列化类型（由topic+headers+ProducerRecord里的value构成），也就是传输数据的序列化方式，建议用String或Bytes即可
    partitioner.class: net.dgg.framework.tac.kafka.producer.DggKafkaPartitioner #自定义分区器
    acks: 1 #默认1,取值[all, -1, 0, 1]，all或-1（等价）表示kafka写入磁盘成功后才返回ack，能够确保数据不丢失；1表示kafka只要接收到数据就返回ack，不能确保写入磁盘；0表示不使用ack也不会retry。
    buffer.memory: 33554432 #数据发送等待的缓冲区大小，该值设置得太小可能会导致异常，默认33554432
    compression.type: none #数据压缩类型，取值none, gzip, snappy, lz4，默认none，批处理的情况压缩效率较高
    retries: 3 #若发送失败的重试次数，批处理情况下可能会改变发送数据的顺序，默认0
    batch.size: 16384 #一次批量传输的最大值，超过这个大小的数据将不会被batch，该值设置得太小会增加网络传输开销，太大则浪费内存空间，具体看传输的数据而定。
    linger.ms: 0 #batch的等待时间，批处理最多等待该毫秒数，消息则被发送出去，若在该时间段内消息大小已经累积到了batch.size,也将被立即发送出去，默认0
    max.request.size: 104857600 #单次请求数据的大小最大值，避免一次性发送过大的数据，会影响到单次请求的batch数量，默认值1048576
    request.timeout.ms: 30000 #请求超时等待重试的时间，默认30000
    max.in.flight.requests.per.connection: 5 #若发送失败的数据超过这个值，则该通讯会被阻塞等待重试发送
    enable.idempotence: false #幂等传输，设置为true的话将会保证只发送成功一次该数据，不会重复发送，设置为true以后max.in.flight.requests.per.connection将会<=5，retries会>0，并且acks会被设置为all（若没有手动设置，则会被系统自动设置成合适的值），默认false
  consumer:
    key.deserializer: org.apache.kafka.common.serialization.StringDeserializer #必填，key序列化类型（由topic+headers+ProducerRecord里的key构成，通常用String即可）
    value.deserializer: org.apache.kafka.common.serialization.ByteArrayDeserializer #必填，value序列化类型（由topic+headers+ProducerRecord里的value构成），也就是传输数据的序列化方式，建议用String或Byte即可
    #auto.offset.reset: latest #当Kafka中没有初始offset或如果当前的offset不存在时（例如，该数据被删除了），该怎么办。earliest：自动将offset重置为最早的偏移；latest（默认）：自动将offset重置为最新偏移；none：如果消费者组找到之前的offset，则向消费者抛出异常。
    #fetch.min.bytes: 1 #服务器拉取请求返回的最小数据量，如果数据不足，请求将等待数据积累直到请求超时才返回。将此值设置的越大将导致服务器等待数据累积的越长，这可能以一些额外延迟为代价提高服务器吞吐量。默认1字节
    #fetch.max.bytes: 52428800 #同上，是最大数据量，但不是绝对的，超过仍将正常返回。接收的最大消息大小通过message.max.bytes(broker config)或 max.message.bytes(topic config)定义。默认52428800字节
    #fetch.max.wait.ms: 1000 #如果没有足够的数据满足fetch.min.bytes，服务器等待的最大时间。
    #default.api.timeout.ms: 60000 #指定可用于阻止的KafkaConsumer API的默认超时
    #receive.buffer.bytes: -1 #读取数据时使用的TCP接收缓冲区（SO_RCVBUF）的大小。 如果值为-1，则将使用OS默认值。
    #send.buffer.bytes: 131072 #同上，是读取数据时候
    #request.timeout.ms: 305000 #客户端等待请求响应的最长时间。 如果在超时之前未收到响应，客户端将在必要时重新发送请求，如果重试耗尽则客户端将返回失败。
    enable.auto.commit: true #见下
    auto.commit.interval.ms: 1000 #如果enable.auto.commit设置为true，则消费者偏移量自动提交给Kafka的频率（以毫秒为单位）。
    #reconnect.backoff.ms: 1000 #尝试重新连接指定主机之前等待的时间，避免频繁的连接主机，这种机制适用于消费者向broker发送的所有请求。
    #reconnect.backoff.max.ms: 5000 #重连最大时限
    #retry.backoff.ms: 1000 #尝试重新发送失败的请求到指定topic分区之前的等待时间。避免在某些故障情况下，频繁的重复发送。